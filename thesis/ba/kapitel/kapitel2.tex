% kapitel2.tex
\chapter{Grundlagen}
\label{chapter:kap2}
\begin{equation}
y_j = \eta(x_j, \theta_0) + \epsilon_j, 
\quad j=1,2,...,n \text{ und } \epsilon \sim N(0, \sigma^2)
\end{equation}

- Quellen: Barton 1998, Krazanowiski 1998\\
- geben sei eine situation, wo ein regression metamodel als repräsentation fpr die ausgabe einer simulations studie verwendet wird\\
- n unabhängige versuche und die beobachteten werte des simulations models seien gegeben durch y\\
- y ist zufallsvariable abhängig von einem design punkt x\\
- eine gewöhnliche darstellung ist durch ... (means of a statistical metamodel)\\
- ein paar beispiele die zur orientierung dienten geben\\
- eta bezeichnet eine deterministische funktion, namentlich regressionsfunktion\\
- genauer gesagt ist eta ein parmetrisches statistisches metamodel\\
- es wird angenommen, dass die simulation durch dieses modell repräsentiert werden kann und der erwartungswert dieses metamodels spiegelt dann den wahren erwartungswert wieder, vorausgesetzt die annahme trifft zu\\
- epsilon bezeichnet den für alle design punkte unabhängigen zufallsfehler mit mean 0\\
- oft wird angenommen dass die varianz für alle design punkte gleich ist, aber nicht zwingend\\
- jedoch mean(epsilon)=0 bedeutet eta gibt den erwartungs wert der statistik an\\
- die berechnung der regressionsfunktion ist primäres ziel der simulations studie\\
- angenommen das modell repräsentiert die simulation und es ex ein wahrer wert theta0, dann ist das erste problem diesen zu bestimmen bzw zu schätzen\\
- die mit abstand effektivste methode theta in parametrischen studien zu schätzen ist die maximum likelyhood methode, welche im nächsten abschnitt kurz vorgestellt werden soll\\

\section{Maximum Likelihood Estimation}
% eine Seite = 40 Zeilen
- gegeben sei eine menge von unabhängigen stichproben, erhalten von verteilungsfunktionen fi\\
- in unserem regressionsfall zb sind die yi werte verteilt mit... sodass wir als verteilungsfunktionen ... erhalten\\
- die joint distribution aus den verteilungsfunktionen bezüglich aller yi ist eine funktion in abhängigkeit von theta und gegeben der stichprobe y und wird likelihood von theta genannt\\
- ziel der mle ist nun diese funktion zu maximieren\\
- das maximum ist durch theta mit ableitung 0 gegebne,da es aber sehr umständlich ist ein produkt abzuleiten, betrachtet man stattdessen den logarithmus der likelihood, welcher sich als summe der einzelnen logarithmen schreiben lässt\\
- da der logarithmus eine streng monoton steigende funktion ist lässt sich der mle nun auch als maximum der loglikelihood bestimmen\\
- ein sehr praktischer ansatz ist nun die bestimmung des maximums mittels numerischer verfahren, die nelder mead methode liefert ein robustes suchverfahren\\
- wichtige erkenntnisse über den mle sind nun dass unter sehr allgemeinen voraussetzungen mle multivariat normalverteilt ist mit mean theta0(wahrer wert) und varianz matrix V(theta0)\\
- wobei V sich als inverse der fischer informations matrix berechnen lässt, welches widerum der erwartungswert der hessischen matrix der loglik ist\\
- V kann durch V(mle) angenähert werden\\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\

\section{Confidence intervals}
\begin{equation}
\mathbb{P} \left( \theta_L \le \theta_0 \le \theta_U \right) \geq 1-\alpha
\end{equation}

\begin{equation}
\theta_L, \theta_U = \hat\theta \mp z_{\alpha/2}
\sqrt{
  V(\hat\theta)
}
\end{equation}

- wenn man ein parametrisches modell gefunden hat, welches die daten reptäsentieren soll, ist eine offensichtliche frage, wie akkurat diese schätzung ist\\
- oft wird ein interval bezgl des schätzers angegeben welches den wahren wert mit gewünschter wahrscheinlichkeit überdeckt\\
- solch ein interval heißt confidence intervall, klassische methoden zur bestimmung eines solchen intervals bauen auf asymtotischer theory und der sogenannten delta methode auf\\
- darstellung von ci zeigen\\
- ein konfindenz intervall für die varianz theta[1] in allen design punkten ist gegeben durch ... da ...\\
- eher interessiert uns allerdings ein confidence interval für die regressionsfunktion \\
- aufgrundlage von asymptotischer theorie (genauer die taylor expansion) und der deltamethode erhalten wir ein confidence interval für eta ...
- herleitung von russel zeigen...\\
- man beachte dass die ableitung und ... durch finite difference methoden berechnet werden könnne\\
- nachteil dieser herangehensweise sind ... -> bootstrap\\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\

\section{Simultaneous Confidence Intervals}
\begin{equation}
\mathbb{P} \left(
  y_L(x) \le \eta(x, \theta_0) \le y_U(x)
\right) \geq 1-\alpha
\quad \forall x \in \mathbb{R}
\end{equation}

\begin{equation}
y_L(x), y_U(x) = \eta(x, \hat\theta) \mp 
z_{\alpha/2} 
\sqrt{
  \left( 
    \frac{\partial\eta(x, \theta)}{\partial\theta} 
  \right)_{\hat\theta}^T 
  V(\hat\theta) 
  \left( 
    \frac{\partial\eta(x, \theta)}{\partial\theta} 
  \right)_{\hat\theta}
}
\end{equation}

- Quellen: Miller 1981\\
- interessanter für uns, als die schätzung von confidence intervallen für die einzelnen design punkte, ist eine schätzung von confidence intervallen, die für alle werte simultan gilt\\
- gesucht ist ein band welches mit gewünschter wahrscheinlichkeit die gesamte regressionsfunktion überdeckt\\
- beispiele von miller 1981 nenen ...\\
- eine einfaches und conservatives confidence band erhält man duch anwendung der taylor reihen expansion und asymptotischer theorie\\
- beispiel von russel zeigen ...\\
- für kleine n aller dings erhält man durch diesen ansatz oft fälschlich höhere werte für die konfidence als der eigentlich berechnete konfidence\\
- bootstrap kann in diesem fall helfen\\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\

\section{Likelihood based Confidence Region}
\begin{equation}
\mathbb{P} \left(
  y_L(x) \le \eta(x, \theta_0) \le y_U(x) 
  \quad \forall x \in \mathbb{R}
\right) \geq 1-\alpha
\end{equation}

\begin{equation}
y_L(x), y_U(x) = \eta(x, \hat\theta) \mp 
\sqrt{
  \chi_p^2(a)
  \left( 
    \frac{\partial\eta(x, \theta)}{\partial\theta} 
  \right)_{\hat\theta}^T 
  V(\hat\theta) 
  \left( 
    \frac{\partial\eta(x, \theta)}{\partial\theta} 
  \right)_{\hat\theta}
}
\end{equation}

\section{Coverage Error}
- die qualität der confindence bereiche wir oft in form sogenannter coverage error beschrieben\\
- diese können durch asymptotische theorie bestimmt werden, auch für die bootstrap versionen\\
- coverage error ist in der regel O(1 / sqrt n) aber kann oft auf O(1 / n) durch balanced ci reduziert werden \\
- coverage error kommt hauptsächlich vom bias, da der effekt entgegengesetzte ist links und rechts von null hebt er sich auf, falls die ci balanciert werden\\
- coverage error kann als maß für den unterschied zwischen erreichter und gewünschter überdeckungswahrscheinlichkeit dienen\\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\
- \\

\section{Basic Bootstrap}
\begin{algorithm} 
  \caption{Basic-Sampling Methode} 
  \label{algo:sampling} 

  \begin{algorithmic}
  	\FOR{$j=0$ to $B$}
      \FOR{$i=0$ to $n$} 
		    \STATE ziehe ein Sample $y_{ij}$ von $F(.)$
		  \ENDFOR
			\STATE berechne die Statistik $s_j = s(y_j)$
    \ENDFOR  
  \end{algorithmic}
\end{algorithm} 

\begin{algorithm} 
  \caption{Bootstrap-Sampling Methode} 
  \label{algo:bootstrap} 

  \begin{algorithmic}
    \REQUIRE zufälliges Sample $y = (y_1, y_2, ...y_n)$ von $F(.)$
    \STATE erstelle die EDF $F_n(.|y)$
		\FOR{$j=0$ to $B$}
			\FOR{$i=0$ to $n$} 
			  \STATE ziehe ein Sample $y^*_{ij}$ von $F_n(.|y)$
			\ENDFOR
			\STATE berechne die Statistik $s^*_j = s(y^*_j)$
		\ENDFOR
		\STATE erstelle die EDF $G_n(.|s*)$ 
  \end{algorithmic}
\end{algorithm} 

\section{Parametric Bootstrap}



























